//! # Lexer - Tokenization of Ruskell Source Code
//!
//! This module defines the lexical tokens used in the Ruskell language using the
//! `lachs` library's `#[token]` derive macro. The lexer automatically converts
//! source code strings into a stream of tokens that the parser consumes.
//!
//! ## Token Categories
//!
//! The tokens are organized into several categories:
//!
//! ### Keywords
//! Reserved words with special meaning:
//! - `do` - Start of a do-block (sequential execution)
//! - `end` - End of a do-block
//! - `if`, `then`, `else` - Conditional expressions
//! - `case`, `of` - Pattern matching expressions
//! - `true`, `false` - Boolean literals
//!
//! ### Identifiers and Literals
//! - `Ident` - Variable and function names: `[a-zA-Z'][a-zA-Z0-9']*`
//! - `Integer` - Numeric literals: `[0-9]+`
//! - `StringLiteral` - String literals with escape sequences: `"[^"\\]*"`
//! - `Underscore` (`_`) - Wildcard pattern
//!
//! ### Operators
//! - Function definition: `=`
//! - Type annotation: `::`
//! - Local binding: `:=`
//! - Lambda: `\`
//! - Lambda arrow: `=>`
//! - String concatenation: `++`
//! - Arithmetic: `+`, `-`, `*`, `/`
//! - Comparison: `==`, `!=`, `<=`, `>=`, `<`, `>`
//! - Logical: `&&`, `||`, `!`
//!
//! ### Punctuation
//! - Parentheses: `(`, `)`
//! - Brackets: `[`, `]`
//! - Comma: `,`
//! - Colon: `:`
//! - Pipe: `|`
//!
//! ## Comments
//!
//! Ruskell supports two types of comments:
//! - Single-line comments: `-- comment text`
//! - Multi-line comments: `{- comment text -}`
//!
//! Multi-line comments can be nested: `{- outer {- inner -} outer -}`
//!
//! Comments are stripped during preprocessing before lexing via the
//! [`strip_comments`] function.
//!
//! ## Usage
//!
//! The lexer is typically used indirectly through the parser:
//!
//! ```ignore
//! use ruskell::parser::parse;
//!
//! let source = r#"
//!     factorial n = n * factorial(n - 1)
//! "#;
//! let program = parse(source)?;
//! ```
//!
//! The `Token` enum is generated by the `#[lachs::token]` attribute macro,
//! which creates the necessary lexer infrastructure.

use lachs::Span;

/// Token types in the Ruskell language
///
/// Each token variant wraps a `Span` (position information) to enable
/// precise error reporting during parsing. The `#[lachs::token]` macro
/// automatically generates the lexer that produces these tokens.
#[lachs::token]
pub enum Token {
    #[terminal("do")]
    Do,
    #[terminal("end")]
    End,
    #[terminal("true")]
    True,
    #[terminal("false")]
    False,
    #[terminal("if")]
    If,
    #[terminal("then")]
    Then,
    #[terminal("else")]
    Else,
    #[terminal("case")]
    Case,
    #[terminal("of")]
    Of,
    #[terminal("_")]
    Underscore,
    #[literal("[a-zA-Z'][a-zA-Z0-9']*")]
    Ident,
    #[literal("[0-9]+")]
    Integer,
    #[literal(r#""([^"\\]|\\.)*""#)]
    StringLiteral,
    #[terminal("=")]
    Equals,
    #[terminal(":")]
    Colon,
    #[terminal("::")]
    DoubleColon,
    #[terminal(":=")]
    Assign,
    #[terminal("\\")]
    Backslash,
    #[terminal("=>")]
    Arrow,
    #[terminal(",")]
    Comma,
    #[terminal("(")]
    LParen,
    #[terminal(")")]
    RParen,
    #[terminal("++")]
    PlusPlus,
    #[terminal("+")]
    Plus,
    #[terminal("-")]
    Minus,
    #[terminal("*")]
    Star,
    #[terminal("/")]
    Slash,
    #[terminal("==")]
    DoubleEquals,
    #[terminal("!=")]
    NotEquals,
    #[terminal("<=")]
    LessEquals,
    #[terminal(">=")]
    GreaterEquals,
    #[terminal("<")]
    LessThan,
    #[terminal(">")]
    GreaterThan,
    #[terminal("&&")]
    LogicalAnd,
    #[terminal("||")]
    LogicalOr,
    #[terminal("!")]
    LogicalNot,
    #[terminal("[")]
    LBracket,
    #[terminal("]")]
    RBracket,
    #[terminal("|")]
    Pipe,
}

/// Strip comments from source code before lexing
///
/// Removes both single-line (`--`) and multi-line (`{- -}`) comments,
/// preserving line numbers for accurate error reporting.
///
/// # Comment Syntax
///
/// - **Single-line comments**: Start with `--` and continue to end of line
/// - **Multi-line comments**: Enclosed in `{-` and `-}`, can be nested
///
/// # Examples
///
/// ```
/// use ruskell::lexer::strip_comments;
///
/// let source = "main = 42 -- this is a comment";
/// let stripped = strip_comments(source);
/// assert_eq!(stripped, "main = 42                     ");
///
/// let source = "x = {- nested {- comment -} here -} 1";
/// let stripped = strip_comments(source);
/// assert_eq!(stripped, "x =                                 1");
/// ```
pub fn strip_comments(source: &str) -> String {
    let mut result = String::with_capacity(source.len());
    let chars: Vec<char> = source.chars().collect();
    let mut i = 0;
    let mut nesting_level = 0;

    while i < chars.len() {
        // Check for multi-line comment start
        if i + 1 < chars.len() && chars[i] == '{' && chars[i + 1] == '-' {
            nesting_level += 1;
            result.push(' ');
            result.push(' ');
            i += 2;
            continue;
        }

        // Check for multi-line comment end
        if i + 1 < chars.len() && chars[i] == '-' && chars[i + 1] == '}' && nesting_level > 0 {
            nesting_level -= 1;
            result.push(' ');
            result.push(' ');
            i += 2;
            continue;
        }

        // Inside multi-line comment
        if nesting_level > 0 {
            if chars[i] == '\n' {
                result.push('\n');
            } else {
                result.push(' ');
            }
            i += 1;
            continue;
        }

        // Check for single-line comment
        if i + 1 < chars.len() && chars[i] == '-' && chars[i + 1] == '-' {
            // Replace comment with spaces until end of line
            while i < chars.len() && chars[i] != '\n' {
                result.push(' ');
                i += 1;
            }
            // Don't skip the newline; it will be added in the next iteration
            continue;
        }

        // Regular character
        result.push(chars[i]);
        i += 1;
    }

    result
}

impl Token {
    /// Returns the source position (span) of this token
    ///
    /// # Returns
    ///
    /// A `Span` containing the start and end positions of this token in the source code.
    /// This is useful for error reporting and debugging.
    pub fn pos(&self) -> Span {
        match self {
            Token::Do(inner) => inner.position.clone(),
            Token::End(inner) => inner.position.clone(),
            Token::Ident(inner) => inner.position.clone(),
            Token::Integer(inner) => inner.position.clone(),
            Token::StringLiteral(inner) => inner.position.clone(),
            Token::Equals(inner) => inner.position.clone(),
            Token::Colon(inner) => inner.position.clone(),
            Token::DoubleColon(inner) => inner.position.clone(),
            Token::Assign(inner) => inner.position.clone(),
            Token::Backslash(inner) => inner.position.clone(),
            Token::Arrow(inner) => inner.position.clone(),
            Token::Comma(inner) => inner.position.clone(),
            Token::LParen(inner) => inner.position.clone(),
            Token::RParen(inner) => inner.position.clone(),
            Token::PlusPlus(inner) => inner.position.clone(),
            Token::Plus(inner) => inner.position.clone(),
            Token::Minus(inner) => inner.position.clone(),
            Token::Star(inner) => inner.position.clone(),
            Token::Slash(inner) => inner.position.clone(),
            Token::True(inner) => inner.position.clone(),
            Token::False(inner) => inner.position.clone(),
            Token::If(inner) => inner.position.clone(),
            Token::Then(inner) => inner.position.clone(),
            Token::Else(inner) => inner.position.clone(),
            Token::Case(inner) => inner.position.clone(),
            Token::Of(inner) => inner.position.clone(),
            Token::Underscore(inner) => inner.position.clone(),
            Token::DoubleEquals(inner) => inner.position.clone(),
            Token::NotEquals(inner) => inner.position.clone(),
            Token::LessEquals(inner) => inner.position.clone(),
            Token::GreaterEquals(inner) => inner.position.clone(),
            Token::LessThan(inner) => inner.position.clone(),
            Token::GreaterThan(inner) => inner.position.clone(),
            Token::LogicalAnd(inner) => inner.position.clone(),
            Token::LogicalOr(inner) => inner.position.clone(),
            Token::LogicalNot(inner) => inner.position.clone(),
            Token::LBracket(inner) => inner.position.clone(),
            Token::RBracket(inner) => inner.position.clone(),
            Token::Pipe(inner) => inner.position.clone(),
        }
    }

    /// Returns a human-readable description of the token
    ///
    /// This is primarily used for error messages to show what token was expected
    /// or encountered during parsing.
    ///
    /// # Returns
    ///
    /// A string representation of the token, with identifiers and literals
    /// showing their actual values.
    ///
    /// # Examples
    ///
    /// ```ignore
    /// Token::Ident(inner).describe() // => "identifier 'factorial'"
    /// Token::Integer(inner).describe() // => "integer '42'"
    /// Token::Equals(inner).describe() // => "'='"
    /// ```
    pub fn describe(&self) -> String {
        match self {
            Token::Do(_) => "'do'".to_string(),
            Token::End(_) => "'end'".to_string(),
            Token::Ident(inner) => format!("identifier '{}'", inner.value),
            Token::Integer(inner) => format!("integer '{}'", inner.value),
            Token::StringLiteral(inner) => format!("string {}", inner.value),
            Token::Equals(_) => "'='".to_string(),
            Token::Colon(_) => "':'".to_string(),
            Token::DoubleColon(_) => "'::'".to_string(),
            Token::Assign(_) => "':='".to_string(),
            Token::Backslash(_) => "'\\'".to_string(),
            Token::Arrow(_) => "'=>'".to_string(),
            Token::Comma(_) => "','".to_string(),
            Token::LParen(_) => "'('".to_string(),
            Token::RParen(_) => "')'".to_string(),
            Token::PlusPlus(_) => "'++'".to_string(),
            Token::Plus(_) => "'+'".to_string(),
            Token::Minus(_) => "'-'".to_string(),
            Token::Star(_) => "'*'".to_string(),
            Token::Slash(_) => "'/'".to_string(),
            Token::True(_) => "'true'".to_string(),
            Token::False(_) => "'false'".to_string(),
            Token::If(_) => "'if'".to_string(),
            Token::Then(_) => "'then'".to_string(),
            Token::Else(_) => "'else'".to_string(),
            Token::Case(_) => "'case'".to_string(),
            Token::Of(_) => "'of'".to_string(),
            Token::Underscore(_) => "'_'".to_string(),
            Token::DoubleEquals(_) => "'=='".to_string(),
            Token::NotEquals(_) => "'!='".to_string(),
            Token::LessEquals(_) => "'<='".to_string(),
            Token::GreaterEquals(_) => "'>='".to_string(),
            Token::LessThan(_) => "'<'".to_string(),
            Token::GreaterThan(_) => "'>'".to_string(),
            Token::LogicalAnd(_) => "'&&'".to_string(),
            Token::LogicalOr(_) => "'||'".to_string(),
            Token::LogicalNot(_) => "'!'".to_string(),
            Token::LBracket(_) => "'['".to_string(),
            Token::RBracket(_) => "']'".to_string(),
            Token::Pipe(_) => "'|'".to_string(),
        }
    }
}
